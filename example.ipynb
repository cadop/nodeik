{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from lib.utils import build_model_tabular_suhan\n",
    "import lib.layers.odefunc_suhan as odefunc\n",
    "\n",
    "SOLVERS = [\"dopri5\"]\n",
    "parser = argparse.ArgumentParser('NodeIK')\n",
    "parser.add_argument(\n",
    "    '--data', choices=['2spirals_1d','2spirals_2d', 'swissroll_1d','swissroll_2d', 'circles_1d', 'circles_2d', '2sines_1d', 'target_1d'],\n",
    "    type=str, default='2spirals_1d'\n",
    ")\n",
    "parser.add_argument(\"--layer_type\", type=str, default=\"concatsquash\", choices=[\"concatsquash\"])\n",
    "parser.add_argument('--dims', type=str, default='64-64-64')\n",
    "parser.add_argument(\"--num_blocks\", type=int, default=1, help='Number of stacked CNFs.')\n",
    "parser.add_argument('--time_length', type=float, default=0.5)\n",
    "parser.add_argument('--train_T', type=eval, default=True)\n",
    "parser.add_argument(\"--divergence_fn\", type=str, default=\"brute_force\", choices=[\"brute_force\", \"approximate\"])\n",
    "parser.add_argument(\"--nonlinearity\", type=str, default=\"tanh\", choices=odefunc.NONLINEARITIES)\n",
    "\n",
    "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
    "parser.add_argument('--atol', type=float, default=1e-5)\n",
    "parser.add_argument('--rtol', type=float, default=1e-5)\n",
    "\n",
    "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
    "parser.add_argument('--rademacher', type=eval, default=False, choices=[True, False])\n",
    "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
    "parser.add_argument('--niters', type=int, default=36000)\n",
    "parser.add_argument('--batch_size', type=int, default=100)\n",
    "parser.add_argument('--test_batch_size', type=int, default=1000)\n",
    "parser.add_argument('--lr', type=float, default=1e-3)\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-5)\n",
    "\n",
    "# for the proposed method\n",
    "parser.add_argument('--std_min', type=float, default=0.0)\n",
    "parser.add_argument('--std_max', type=float, default=0.1)\n",
    "parser.add_argument('--std_weight', type=float, default=2)\n",
    "\n",
    "parser.add_argument('--viz_freq', type=int, default=100)\n",
    "parser.add_argument('--val_freq', type=int, default=400)\n",
    "parser.add_argument('--log_freq', type=int, default=10)\n",
    "parser.add_argument('--gpu', type=int, default=0)\n",
    "args = parser.parse_args([])\n",
    "\n",
    "device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "\n",
    "class Learner(pl.LightningModule):\n",
    "    def __init__(self, model:nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.iters = 0\n",
    "\n",
    "model = build_model_tabular_suhan(args, 7).to(device)\n",
    "learn = Learner.load_from_checkpoint('model/panda_sample_model.ckpt',model=model)\n",
    "model.eval()\n",
    "model.chain[0].odefunc.odefunc.calc_density = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NODE IK Inference example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. single inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin_c tensor([ 0.6195, -0.0165,  0.8672,  0.4766,  0.4998,  0.7225, -0.0326],\n",
      "       device='cuda:0')\n",
      "evals 56.0\n",
      "after q tensor([[-0.7690,  1.0532,  2.1321, -0.9949, -0.7733,  2.5012, -0.3983]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([16.4922], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "time 296.3862419128418 ms\n"
     ]
    }
   ],
   "source": [
    "input_pose = np.array([6.1946e-01, -1.6464e-02,  8.6722e-01,  4.7658e-01,  4.9979e-01,  7.2251e-01, -3.2554e-02])\n",
    "\n",
    "max_len = 1\n",
    "z = torch.normal(0, 1, size=(max_len, 7)).to(device)\n",
    "c = torch.from_numpy(input_pose).float().to(device)\n",
    "print('origin_c',c)\n",
    "cc = torch.stack([c]*max_len).to(device)\n",
    "zero = torch.zeros(z.shape[0], 1).to(z)\n",
    "\n",
    "start_2 = time.time()\n",
    "model.chain[0].odefunc.odefunc.calc_density = True\n",
    "xx, delta_logp = model(z, cc, zero,reverse=True)\n",
    "end_2 = time.time()\n",
    "evals = model.chain[0].num_evals()\n",
    "print('evals',evals)\n",
    "print('after q', xx[:max_len,:])\n",
    "print(delta_logp[:max_len,0])\n",
    "print('time',(end_2 - start_2) * 1000,'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. multiple inference (512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin_c tensor([ 0.6195, -0.0165,  0.8672,  0.4766,  0.4998,  0.7225, -0.0326],\n",
      "       device='cuda:0')\n",
      "evals 56.0\n",
      "time 310.81295013427734 ms\n"
     ]
    }
   ],
   "source": [
    "input_pose = np.array([6.1946e-01, -1.6464e-02,  8.6722e-01,  4.7658e-01,  4.9979e-01,  7.2251e-01, -3.2554e-02])\n",
    "\n",
    "max_len = 512\n",
    "z = torch.normal(0, 1, size=(max_len, 7)).to(device)\n",
    "c = torch.from_numpy(input_pose).float().to(device)\n",
    "print('origin_c',c)\n",
    "cc = torch.stack([c]*max_len).to(device)\n",
    "zero = torch.zeros(z.shape[0], 1).to(z)\n",
    "\n",
    "start_2 = time.time()\n",
    "model.chain[0].odefunc.odefunc.calc_density = True\n",
    "xx, delta_logp = model(z, cc, zero,reverse=True)\n",
    "end_2 = time.time()\n",
    "evals = model.chain[0].num_evals()\n",
    "print('evals',evals)\n",
    "# print('after q', xx[:max_len,:])\n",
    "# print(delta_logp[:max_len,0])\n",
    "print('time',(end_2 - start_2) * 1000,'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. multiple inference (32 k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin_c tensor([ 0.6195, -0.0165,  0.8672,  0.4766,  0.4998,  0.7225, -0.0326],\n",
      "       device='cuda:0')\n",
      "evals 68.0\n",
      "time 759.4811916351318 ms\n"
     ]
    }
   ],
   "source": [
    "input_pose = np.array([6.1946e-01, -1.6464e-02,  8.6722e-01,  4.7658e-01,  4.9979e-01,  7.2251e-01, -3.2554e-02])\n",
    "\n",
    "max_len = 32768\n",
    "z = torch.normal(0, 1, size=(max_len, 7)).to(device)\n",
    "c = torch.from_numpy(input_pose).float().to(device)\n",
    "print('origin_c',c)\n",
    "cc = torch.stack([c]*max_len).to(device)\n",
    "zero = torch.zeros(z.shape[0], 1).to(z)\n",
    "\n",
    "start_2 = time.time()\n",
    "model.chain[0].odefunc.odefunc.calc_density = True\n",
    "xx, delta_logp = model(z, cc, zero,reverse=True)\n",
    "end_2 = time.time()\n",
    "evals = model.chain[0].num_evals()\n",
    "print('evals',evals)\n",
    "# print('after q', xx[:max_len,:])\n",
    "# print(delta_logp[:max_len,0])\n",
    "print('time',(end_2 - start_2) * 1000,'ms')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66952a0c7f484636660c89a57764d16cc4bd857f3a07987fc17310c8083aad7e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('suhan38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
